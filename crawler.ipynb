{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from pydub import AudioSegment, silence\n",
    "import os\n",
    "import json\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0\",\n",
    "    \"cookie\": \"_ga=GA1.1.1817152003.1724338082; pgv_pvid=4256099520; .AspNetCore.Session=CfDJ8Pc25MTayhNEuFUwBGxHcQybVNcgp6QXOvls6LLt8NiqMiM7g4bQ8IAXMYpf%2F2%2Bn0V6mQZ1Ta%2BjG1gysALpjV1FWy1lt5ddw%2F9UC9JLXqlASYCjqZ%2F%2Br6qMZ5ShiFDmzCPSQeLCu0YAHzqPbitKv6N8V1P0wItubpTyzJSimkjSe; __qc_wId=261; EudicWebSession=QYNeyJoYXNfb2xkX3Bhc3N3b3JkIjpmYWxzZSwidG9rZW4iOiJqRWZrTFZUZzVSbkJPcHdJN29XcVY5amxsemc9IiwiZXhwaXJlaW4iOjEzMTQwMDAsInVzZXJpZCI6IjM4ODU0YTcxLTU2MjYtMTFlZS1iYjUzLTAwNTA1Njg2YWU5YiIsInVzZXJuYW1lIjoi5a2Q5oGSX2RFcmMwUDlFOE1RMyIsImNyZWF0aW9uX2RhdGUiOiIyMDIzLTA5LTE4VDA1OjIxOjE0WiIsInJvbGVzIjpudWxsLCJvcGVuaWRfdHlwZSI6bnVsbCwib3BlbmlkX2Rlc2MiOm51bGwsInByb2ZpbGUiOnsibmlja25hbWUiOiLlrZDmgZIiLCJlbWFpbCI6IiIsImdlbmRlciI6IuWlsyIsInBhc3N3b3JkIjpudWxsLCJ2b2NhYnVsYXJpZXMiOnt9fSwibGFzdF9wYXNzd29yZF9jaGFuZ2VkX2RhdGUiOiI5LzE4LzIwMjMgMToyMToxNCBQTSIsInJlZGlyZWN0X3VybCI6bnVsbH0%253d; .AspNetCore.Antiforgery.W85QSzz26FE=CfDJ8Pc25MTayhNEuFUwBGxHcQwC5Eg70g99eLhWzXRc68acfd_szKjY8ZUmKWsEGLKpXEtAnrGl-uJ7_GVwRdYxJuyuXOGFSdm_0qT4t7RC-l1vhlU1O-lfgLH1MAg_qsxviF_PugzXbX3x1gqv2uE0F08; _ga_73H19QCX9F=GS1.1.1724832934.8.1.1724832935.0.0.0\"\n",
    "}\n",
    "with open(data_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def fixed_encode_uri_component(n):\n",
    "    return quote(n).replace('%21', '!').replace('%27', \"'\").replace('%28', '(').replace('%29', ')').replace('%2A', '*')\n",
    "\n",
    "def get_txt(word):\n",
    "    return fixed_encode_uri_component(base64.b64encode(word.encode()).decode())\n",
    "\n",
    "for tense, types in data.items():\n",
    "    if tense == \"ip\":\n",
    "        pp_list = [\"je\", \"tu\", \"il singulier\", \"nous\", \"vous\", \"ils pluriel\"]\n",
    "    elif tense == \"imp\":\n",
    "        pp_list = [\"tu\", \"nous\", \"vous\"]\n",
    "    if not os.path.exists(tense):\n",
    "        os.mkdir(tense)\n",
    "    for type, words in types.items():\n",
    "        if not os.path.exists(os.path.join(tense, type)):\n",
    "            os.mkdir(os.path.join(tense, type))\n",
    "        for word in words:\n",
    "            file_path = os.path.join(tense, type, word)\n",
    "            if not os.path.exists(file_path):\n",
    "                os.mkdir(file_path)\n",
    "            if tense == \"ip\":\n",
    "                which_cg = \"1\"\n",
    "                segments_len = 7\n",
    "            elif tense == \"imp\":\n",
    "                which_cg = \"8\"\n",
    "                segments_len = 4\n",
    "\n",
    "            if type == \"vp\":\n",
    "                origin_url = f\"https://api.frdic.com/api/v2/speech/speakweb?langid=fr&txt=QYN{get_txt(word)}\"\n",
    "                origin_res = requests.get(origin_url, headers=headers)\n",
    "                assert(origin_res.status_code == 200)\n",
    "                with open(\"tmp.mp3\", \"wb\") as f:\n",
    "                    f.write(origin_res.content)\n",
    "                audio = AudioSegment.from_mp3(\"tmp.mp3\")\n",
    "                assert(origin_res.status_code == 200)\n",
    "                for index, pp in enumerate(pp_list):\n",
    "                    pp_path = os.path.join(\"pp\", pp + \".mp3\")\n",
    "                    pp_audio = AudioSegment.from_mp3(pp_path)\n",
    "                    file = os.path.join(file_path, \"q\" + str(index + 1) + \"_\" + word + \" (\" + pp + \")\" + \".mp3\")\n",
    "                    (audio + pp_audio).export(file, format='mp3')\n",
    "\n",
    "                word = word.split(\" \")[1]\n",
    "                base_url = f\"https://www.frdic.com/dicts/cg/{word}?forcecg=true\"\n",
    "                base_res = requests.get(base_url, headers=headers)\n",
    "                assert(base_res.status_code == 200)\n",
    "                base_soup = BS(base_res.content, \"html.parser\")\n",
    "\n",
    "                page_status = base_soup.find(\"input\", {\"type\": \"hidden\", \"id\": \"page-status\"})\n",
    "                assert(page_status.has_attr(\"value\"))\n",
    "                page_url = f\"https://www.frdic.com/Dicts/TabWithCgIdx\"\n",
    "                data = {\n",
    "                    \"whichcg\": which_cg,\n",
    "                    \"pagestatus\": page_status[\"value\"],\n",
    "                }\n",
    "                page_res = requests.get(page_url, headers=headers, data=data)\n",
    "                assert(page_res.status_code == 200)\n",
    "                page_soup = BS(page_res.content, \"html.parser\")\n",
    "\n",
    "                word_div = page_soup.find(\"div\", {\"id\": \"elCgMainChild\", \"class\": \"child\"})\n",
    "                words_array = [\"\"]\n",
    "                index = 0\n",
    "                for element in word_div:\n",
    "                    if element.name == \"br\":\n",
    "                        words_array.append(\"\")\n",
    "                        index += 1\n",
    "                    else:\n",
    "                        words_array[index] += element.text\n",
    "                words_array.insert(0, word)\n",
    "                words_array = [word.strip() for word in words_array]\n",
    "                for index, phrase in enumerate(words_array):\n",
    "                    if index == 0:\n",
    "                        continue\n",
    "                    phrase_array = phrase.split(\" \")\n",
    "                    if phrase_array[0] == \"Je\":\n",
    "                        pr = \"me\"\n",
    "                    elif phrase_array[0] == \"Tu\":\n",
    "                        pr = \"te\"\n",
    "                    elif phrase_array[0] == \"Il\" or phrase_array[0] == \"Ils\":\n",
    "                        pr = \"se\"\n",
    "                    elif phrase_array[0] == \"Nous\":\n",
    "                        pr = \"nous\"\n",
    "                    elif phrase_array[0] == \"Vous\":\n",
    "                        pr = \"vous\"\n",
    "                    phrase_array.insert(1, pr)\n",
    "                    phrase = \" \".join(phrase_array)\n",
    "                    audio_url = f\"https://api.frdic.com/api/v2/speech/speakweb?langid=fr&txt=QYN{get_txt(phrase)}\"\n",
    "                    print(audio_url)\n",
    "                    audio_res = requests.get(audio_url, headers=headers)\n",
    "                    assert(audio_res.status_code == 200)\n",
    "                    file = os.path.join(file_path, \"a\" + str(index) + \"_\" + phrase + \".mp3\")\n",
    "                    with open(file, \"wb\") as f:\n",
    "                        f.write(audio_res.content)\n",
    "            else:\n",
    "                base_url = f\"https://www.frdic.com/dicts/cg/{word}?forcecg=true\"\n",
    "                base_res = requests.get(base_url, headers=headers)\n",
    "                assert(base_res.status_code == 200)\n",
    "                base_soup = BS(base_res.content, \"html.parser\")\n",
    "\n",
    "                page_status = base_soup.find(\"input\", {\"type\": \"hidden\", \"id\": \"page-status\"})\n",
    "                assert(page_status.has_attr(\"value\"))\n",
    "                page_url = f\"https://www.frdic.com/Dicts/TabWithCgIdx\"\n",
    "                data = {\n",
    "                    \"whichcg\": which_cg,\n",
    "                    \"pagestatus\": page_status[\"value\"],\n",
    "                }\n",
    "                page_res = requests.get(page_url, headers=headers, data=data)\n",
    "                assert(page_res.status_code == 200)\n",
    "                page_soup = BS(page_res.content, \"html.parser\")\n",
    "\n",
    "                word_div = page_soup.find(\"div\", {\"id\": \"elCgMainChild\", \"class\": \"child\"})\n",
    "                words_array = [\"\"]\n",
    "                index = 0\n",
    "                for element in word_div:\n",
    "                    if element.name == \"br\":\n",
    "                        words_array.append(\"\")\n",
    "                        index += 1\n",
    "                    else:\n",
    "                        words_array[index] += element.text\n",
    "                words_array.insert(0, word)\n",
    "                words_array = [word.strip() for word in words_array]\n",
    "\n",
    "                tense_button = page_soup.find(\"a\", {\"class\": \"voice-js voice-button\", \"title\": \"变位发音\"})\n",
    "                assert(tense_button.has_attr(\"data-rel\"))\n",
    "                tense_url = f\"https://api.frdic.com/api/v2/speech/speakweb?{tense_button['data-rel']}\"\n",
    "                tense_res = requests.get(tense_url, headers=headers)\n",
    "                assert(tense_res.status_code == 200)\n",
    "\n",
    "                with open(\"tmp.mp3\", \"wb\") as f:\n",
    "                    f.write(tense_res.content)\n",
    "\n",
    "                audio = AudioSegment.from_mp3(\"tmp.mp3\")\n",
    "                segments = silence.split_on_silence(audio, silence_thresh=-40, min_silence_len=500)\n",
    "                assert(len(segments) == segments_len)\n",
    "\n",
    "                for i, segment in enumerate(segments):\n",
    "                    if i == 0:\n",
    "                        for j, pp in enumerate(pp_list):\n",
    "                            pp_path = os.path.join(\"pp\", pp + \".mp3\")\n",
    "                            pp_audio = AudioSegment.from_mp3(pp_path)\n",
    "                            segment_file = os.path.join(file_path, \"q\" + str(j + 1) + \"_\" + words_array[i] + \" (\" + pp + \")\" + \".mp3\")\n",
    "                            (segment + pp_audio).export(segment_file, format='mp3')\n",
    "                    else:\n",
    "                        segment_file = os.path.join(file_path, \"a\" + str(i) + \"_\" + words_array[i] + \".mp3\")\n",
    "                        segment.export(segment_file, format='mp3')\n",
    "os.remove(\"tmp.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "from urllib.parse import quote\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0\",\n",
    "}\n",
    "\n",
    "def fixed_encode_uri_component(n):\n",
    "    return quote(n).replace('%21', '!').replace('%27', \"'\").replace('%28', '(').replace('%29', ')').replace('%2A', '*')\n",
    "\n",
    "def get_txt(word):\n",
    "    return fixed_encode_uri_component(base64.b64encode(word.encode()).decode())\n",
    "\n",
    "if not os.path.exists(\"pp\"):\n",
    "    os.mkdir(\"pp\")\n",
    "\n",
    "word_list = [\"je\", \"tu\", \"il singulier\", \"nous\", \"vous\", \"ils pluriel\"]\n",
    "\n",
    "for word in word_list:\n",
    "    file_path = os.path.join(\"pp\", word + \".mp3\")\n",
    "\n",
    "    url = f\"https://api.frdic.com/api/v2/speech/speakweb?langid=fr&txt=QYN{get_txt(word)}\"\n",
    "    print(url)\n",
    "    res = requests.get(url, headers=headers)\n",
    "    assert(res.status_code == 200)\n",
    "\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
